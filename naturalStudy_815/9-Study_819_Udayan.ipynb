{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36e2aee-dfeb-4baa-84ec-cb22b74f1694",
   "metadata": {},
   "source": [
    "# Solution for Predicting Olympic Medal Count\n",
    "We have a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2012. We want to predict the number of medals for the 2016 Olympic Games. The dataset can be divided in three tables, the ground truth, country of olympics and the specific event with medals.\\\n",
    "Here are the attributes of our tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decddabc-7c52-42c3-9114-f1ac7b5574b2",
   "metadata": {},
   "source": [
    "<p><c>\n",
    "    <img src=\"dataset.png\" alt=\"Olympic Logo\" width=500/>\n",
    "</c></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523aa98-2da1-43a1-82b8-0a3b7c4453c9",
   "metadata": {},
   "source": [
    "Here we provide a solution for predicting Olympic Medal Count in 2016. Now you need to **follow the provided solution and select a subset of features** you think is helpful for predicting the Medal Count of the coming Olympic Games  in Tokyo. You are required to finish the tasks below:\n",
    "### Steps:\n",
    "\n",
    "#### 1. learn about the dataset and the task of predicting Olympic Medal Count in the first cell called load data (input, ground truth, data, regressive model);\n",
    "#### 2. load the suggested features from experts and Automatic algorithms and <span style=\"color:blue\">check the features in the 3rd cell by clicking the button on the right of the cell</span>.\n",
    "#### 3. Checked the information of the features in the table view and select a subset of features by ticking the checkbox, submit your selection by clicking the <span style=\"color:blue\">blue button Submit Selection in the view</span>.\n",
    "#### 4. Copy the feature ids and evaluate these features in the evaluation cell by pasting the id list in the <span style=\"color:blue\">auto_human_feature_matrix.iloc[:,[feature id list]</span>.\n",
    "\n",
    "#### You can select and evaluate the features iteratively or create new features from the three tables by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7926275-0806-41dc-96dc-7d740131a9f8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3be622-719b-4c91-a9a6-05d883f9992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and groung truth\n",
    "import os\n",
    "import pandas as pd\n",
    "import utils_original as utils\n",
    "import foldCode1 as load_df\n",
    "import foldCode2 as our_model\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(),\"data/olympic_games_data\")\n",
    "es = utils.load_entityset(data_dir=DATA_DIR)\n",
    "groundtruth_table, countries_table, events_table, cutoff_times_gt, dates, labels = load_df.loadData(es, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad40b99-8bc7-4de4-a0e5-315d7a313e10",
   "metadata": {},
   "source": [
    "You can add new cells to print the 3 tables (groundtruth_table, countries_table, events_table) and the input (dates) and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919bb20-cb6f-44a0-b32e-6c0b82c535c6",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\">Generate Features</span> (Edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc137103-136d-4199-91c6-64876537fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_human_feature_names, select_human_features = load_df.human_features() #7\n",
    "all_features = pd.read_csv(\"features/natural_features_all_815.csv\")\n",
    "\n",
    "# Check feature matrix\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730c7d5-0c7e-44ac-ba17-fe0ee5508875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417f6d0-74ff-4f63-83a9-c05b3016b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: write new features\n",
    "# all_features.insert()\n",
    "\n",
    "# OPTIONAL: you can check single feature:\n",
    "# all_features.iloc[:, #id]\n",
    "\n",
    "# MUST EDIT: feature selection: input feature ID in the list below:\n",
    "feature_id = [] # index 0-98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aabd46-271c-4932-b2dc-83ba18719aee",
   "metadata": {},
   "source": [
    "## Evaluate features with given models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb9649-6b61-416b-be80-40be4ac06d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import ARDRegression\n",
    "import utils_original as utils\n",
    "\n",
    "# parameters of the regressive model\n",
    "pipeline_preprocessing = [(\"imputer\",\n",
    "                            SimpleImputer()),\n",
    "                            (\"scaler\", RobustScaler(with_centering=True))]\n",
    "splitter = utils.TimeSeriesSplitByDate(dates=dates, earliest_date=pd.Timestamp('01/01/2012')) \n",
    "\n",
    "# If you want to input all features\n",
    "# all_X = all_features.values  \n",
    "\n",
    "# Take your selection as input\n",
    "all_X = all_features.iloc[:, feature_id].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63bf06c-d8d1-4549-a359-873972cde0d0",
   "metadata": {},
   "source": [
    "### Run Models <span style=\"color:brown\">(No changes to code are required)</span>\n",
    "If you don't want to use a model, you can comment specific lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f3a22-203e-466d-8a17-067439c0a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "rf_regressor = RandomForestRegressor(n_estimators=300, random_state=50)  \n",
    "pipeline_reg0 = Pipeline(pipeline_preprocessing + [('rf_reg', rf_regressor)])\n",
    "regression_score = utils.fit_and_score(all_X, labels, splitter, pipeline_reg0)\n",
    "print(\"RandomForest Reg:\", regression_score)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Linear Regression\n",
    "# linear_reg = LinearRegression()\n",
    "# pipeline_reg1 = Pipeline(pipeline_preprocessing + [('linear_reg', linear_reg)])\n",
    "# regression_score1 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg1)\n",
    "# print(\"Linear Reg: \", regression_score1)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_reg = LogisticRegression()\n",
    "pipeline_reg2 = Pipeline(pipeline_preprocessing + [('logistic_reg', logistic_reg)])\n",
    "regression_score2 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg2)\n",
    "print(\"Logistic Reg: \", regression_score2)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# SGD Regression\n",
    "sgd_reg = SGDRegressor()\n",
    "pipeline_reg3 = Pipeline(pipeline_preprocessing + [('sgd_reg', sgd_reg)])\n",
    "regression_score3 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg3)\n",
    "print(\"SGD Reg: \", regression_score3) \n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# KNN Regression\n",
    "# knn_reg = KNeighborsRegressor()\n",
    "# pipeline_reg4 = Pipeline(pipeline_preprocessing + [('knn_reg', knn_reg)])\n",
    "# regression_score4 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg4)\n",
    "# print(\"KNN Reg: \", regression_score4)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# MLP Regression\n",
    "mlp_reg = MLPRegressor()\n",
    "pipeline_reg5 = Pipeline(pipeline_preprocessing + [('mlp_reg', mlp_reg)])\n",
    "regression_score5 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg5)\n",
    "print(\"MLP Reg: \", regression_score5)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# DecisionTree Regression\n",
    "decisionTree_reg = DecisionTreeRegressor()\n",
    "pipeline_reg6 = Pipeline(pipeline_preprocessing + [('decisionTree_reg', decisionTree_reg)])\n",
    "regression_score6 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg6)\n",
    "print(\"decisionTree Reg: \", regression_score6)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ExtTree Regression\n",
    "extTree_reg = ExtraTreeRegressor()\n",
    "pipeline_reg7 = Pipeline(pipeline_preprocessing + [('extTree_reg', extTree_reg)])\n",
    "regression_score7 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg7)\n",
    "print(\"ExtTree Reg: \", regression_score7)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# GradientBoosting Regression\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "pipeline_reg8 = Pipeline(pipeline_preprocessing + [('gb_reg', gb_reg)])\n",
    "regression_score8 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg8)\n",
    "print(\"GradientBoosting Reg: \", regression_score8)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# LinearSVC Regression\n",
    "# svc_reg = LinearSVC()\n",
    "# pipeline_reg9 = Pipeline(pipeline_preprocessing + [('svc_reg', svc_reg)])\n",
    "# regression_score9 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg9)\n",
    "# print(\"svc Reg: \", regression_score9)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# LinearSVR Regression\n",
    "svr_reg = LinearSVR()\n",
    "pipeline_reg10 = Pipeline(pipeline_preprocessing + [('svr_reg', svr_reg)])\n",
    "regression_score10 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg10)\n",
    "print(\"svr Reg: \", regression_score10)\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ARD Regression\n",
    "ard_reg = ARDRegression()\n",
    "pipeline_reg11 = Pipeline(pipeline_preprocessing + [('ard_reg', ard_reg)])\n",
    "regression_score11 = utils.fit_and_score(all_X, labels, splitter, pipeline_reg11)\n",
    "print(\"ard Reg: \", regression_score11)\n",
    "# --------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125abdf-f181-44ec-b832-832c7abe2373",
   "metadata": {},
   "source": [
    "### Check the importance score of selected features (Select a model and get the score of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84b392-ae34-4014-bfc0-7a71f69f49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = utils.get_feature_importances(pipeline_reg0,                     # select the regressive model for computing important scores of features (Default: RandomForest)\n",
    "#                                               all_features,                  # Compute the score of all features\n",
    "                                            all_features.iloc[:, feature_id], # Compute the score of selected features: \n",
    "                                            labels, splitter, 100)\n",
    " \n",
    "test_date = pd.Timestamp('08/05/2016')\n",
    "feature_imp[test_date].reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
